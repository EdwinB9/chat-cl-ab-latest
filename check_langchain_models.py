"""
Script para verificar qu√© modelos soporta LangChain.
"""

import sys
import os

# Configurar codificaci√≥n UTF-8 para Windows
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

print("üîç Verificando modelos soportados por LangChain...\n")

# Verificar OpenAI
print("=" * 60)
print("üìã MODELOS DE OPENAI (ChatOpenAI)")
print("=" * 60)
try:
    from langchain_openai import ChatOpenAI
    print("‚úÖ langchain-openai est√° instalado")
    
    # Modelos comunes de OpenAI que soporta ChatOpenAI
    openai_models = [
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-4-turbo",
        "gpt-4",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-16k"
    ]
    
    print("\nüìù Modelos com√∫nmente soportados por ChatOpenAI:")
    for model in openai_models:
        print(f"   - {model}")
    
    print("\nüí° Nota: ChatOpenAI acepta cualquier nombre de modelo v√°lido de OpenAI.")
    print("   Los modelos disponibles dependen de tu cuenta y plan de OpenAI.")
    
except ImportError:
    print("‚ùå langchain-openai no est√° instalado")
    print("   Instala con: pip install langchain-openai")

print("\n" + "=" * 60)
print("üìã MODELOS DE GEMINI (ChatGoogleGenerativeAI)")
print("=" * 60)
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    print("‚úÖ langchain-google-genai est√° instalado")
    
    # Modelos comunes de Gemini
    gemini_models = [
        "gemini-pro",
        "gemini-1.5-pro",
        "gemini-1.5-flash",
        "gemini-1.5-flash-latest",
        "gemini-1.5-pro-latest"
    ]
    
    print("\nüìù Modelos com√∫nmente soportados por ChatGoogleGenerativeAI:")
    for model in gemini_models:
        print(f"   - {model}")
    
    print("\nüí° Nota: ChatGoogleGenerativeAI acepta cualquier nombre de modelo v√°lido de Gemini.")
    print("   Los modelos disponibles dependen de tu API key y acceso a Google Cloud.")
    
except ImportError:
    print("‚ùå langchain-google-genai no est√° instalado")
    print("   Instala con: pip install langchain-google-genai")

print("\n" + "=" * 60)
print("üìã VERIFICACI√ìN DE MODELOS EN NUESTRA APP")
print("=" * 60)

try:
    from app.utils.langchain_agent import LangChainAgent
    
    print("\n‚úÖ Nuestros modelos configurados para OpenAI:")
    openai_models = LangChainAgent.get_available_models("openai")
    for key, value in openai_models.items():
        print(f"   - {key}")
    
    print("\n‚úÖ Nuestros modelos configurados para Gemini (gratuitos):")
    gemini_models = LangChainAgent.get_available_models("gemini")
    for key, value in gemini_models.items():
        print(f"   - {key}")
    
except Exception as e:
    print(f"‚ùå Error al verificar modelos: {str(e)}")

print("\n" + "=" * 60)
print("üí° RECOMENDACIONES")
print("=" * 60)
print("""
1. Para OpenAI:
   - Usa modelos que est√©n disponibles en tu cuenta
   - gpt-4o-mini es el m√°s econ√≥mico y recomendado
   - gpt-3.5-turbo es el est√°ndar m√°s econ√≥mico

2. Para Gemini:
   - Usa solo modelos gratuitos si quieres evitar costos
   - gemini-1.5-flash es el m√°s r√°pido y recomendado
   - gemini-1.5-pro es m√°s potente pero con l√≠mites

3. Si un modelo no funciona:
   - Verifica que est√© disponible en tu cuenta
   - Revisa que tu API key tenga acceso
   - Considera usar modelos alternativos
""")

